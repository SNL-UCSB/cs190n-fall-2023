{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68765e8a",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "In this assignment you will be writing netunicorn experiments to measure 'latency-under-load'.  \n",
    "\n",
    "Please submit a PDF verion of this notebook with all the cells evaluated and answers displayed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ba797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "import requests \n",
    "import re\n",
    "import logging\n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "from sys import platform\n",
    "import os, sys\n",
    "import logging\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import signal\n",
    "from typing import Dict\n",
    "\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base.task import Failure, Task, TaskDispatcher\n",
    "\n",
    "\n",
    "from netunicorn.client.remote import RemoteClient, RemoteClientException\n",
    "from netunicorn.base import Experiment, ExperimentStatus, Pipeline\n",
    "from netunicorn.library.tasks.basic import SleepTask\n",
    "from netunicorn.library.tasks.measurements.ookla_speedtest import SpeedTest\n",
    "from netunicorn.library.tasks.measurements.ping import Ping\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base.task import Failure, Task, TaskDispatcher\n",
    "from netunicorn.base import Result, Failure, Success, Task, TaskDispatcher\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from enum import IntEnum\n",
    "from datetime import datetime\n",
    "\n",
    "from returns.pipeline import is_successful\n",
    "from returns.result import Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2097c",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "We have defined two helper functions for executing pipelines and displaying the results from the pipeline execution that you may use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pipeline(pipeline, working_node, experiment_label):\n",
    "    client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "    nodes = client.get_nodes()\n",
    "    working_nodes = nodes.filter(lambda node: node.name.startswith(working_node)).take(1)\n",
    "    experiment = Experiment().map(pipeline, working_nodes)\n",
    "\n",
    "    try:\n",
    "        client.delete_experiment(experiment_label)\n",
    "    except RemoteClientException:\n",
    "        pass\n",
    "\n",
    "    # Prepare Experiment\n",
    "    client.prepare_experiment(experiment, experiment_label)\n",
    "    while True:\n",
    "        info = client.get_experiment_status(experiment_label)\n",
    "        print(info.status)\n",
    "        if info.status == ExperimentStatus.READY:\n",
    "            break\n",
    "        time.sleep(20)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Execute Experiment\n",
    "    client.start_execution(experiment_label)\n",
    "    while True:\n",
    "        info = client.get_experiment_status(experiment_label)\n",
    "        print(info.status)\n",
    "        if info.status != ExperimentStatus.RUNNING:\n",
    "            break\n",
    "        time.sleep(20)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc03216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(info):\n",
    "    # Get Results\n",
    "    for report in info.execution_result:\n",
    "        print(f\"Node name: {report.node.name}\")\n",
    "        print(f\"Error: {report.error}\")\n",
    "\n",
    "        if report.result is None:\n",
    "            print(\"report.result is EMPTY..\")\n",
    "            continue\n",
    "\n",
    "        result, log = report.result  # report stores results of execution and corresponding log\n",
    "\n",
    "        # result is a returns.result.Result object, could be Success of Failure\n",
    "        print(f\"Result is: {type(result)}\")\n",
    "        if is_successful(result):\n",
    "            data = result.unwrap()\n",
    "        else:\n",
    "            data = result.failure()\n",
    "        try:\n",
    "            for key, value in data.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        except:\n",
    "            print(f\"No attribute 'items' in result\")\n",
    "\n",
    "        # we also can explore logs\n",
    "        for line in log:\n",
    "            print(line.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de45fb3",
   "metadata": {},
   "source": [
    "### Task 0\n",
    "Set your credentials for accessing the UCSB netUnicorn deployment below. View the working nodes and choose 1 working node that you will be using for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c457ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in your login / password below\n",
    "netunicorn_login = '<fill me in>'\n",
    "netunicorn_password = '<fill me in>'\n",
    "\n",
    "NETUNICORN_ENDPOINT = os.environ.get('NETUNICORN_ENDPOINT', 'https://pinot.cs.ucsb.edu/netunicorn')\n",
    "NETUNICORN_LOGIN = os.environ.get('NETUNICORN_LOGIN', netunicorn_login)\n",
    "NETUNICORN_PASSWORD = os.environ.get('NETUNICORN_PASSWORD', netunicorn_password)\n",
    "\n",
    "client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "print(\"Health Check: {}\".format(client.healthcheck()))\n",
    "nodes = client.get_nodes()\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the name of your working node\n",
    "working_node = '<fill me in>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c8f98",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Create a pipeline to collect latency data to Google's public DNS (8.8.8.8) from your working node using the [Ping](https://github.com/netunicorn/netunicorn-library/blob/main/tasks/measurements/ping.py) task.   \n",
    "Report the average latency over 5 ICMP probes to the address 8.8.8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3982dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the correct arguments for the Ping() task\n",
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(Ping())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = execute_pipeline(pipeline, working_node, 'ping_experiment')\n",
    "display_results(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill the latency samples array with the latency values returned by the Ping task\n",
    "latency_samples = [\n",
    "    0.0,\n",
    "    0.0,\n",
    "    0.0,\n",
    "    0.0,\n",
    "    0.0\n",
    "]\n",
    "print(\"Average Latency: {:.4f} ms\".format(np.mean(latency_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3081bcc4",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Now we will define a new task, StartBackgroundPing that behaves similar to the Ping task, however it starts the process in the background, so further tasks in the pipeline will execute in parallel with our latency measurements.  \n",
    "\n",
    "Implement the **run()** function in the **StartBackgroundPingLinuxImplementation** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartBackgroundPing(TaskDispatcher):\n",
    "    def __init__(self, address: str, filepath: str, timeout: int = 120, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.address = address\n",
    "        self.filepath = filepath\n",
    "        self.timeout = timeout\n",
    "        self.linux_implementation = StartBackgroundPingLinuxImplementation(\n",
    "            address=self.address,\n",
    "            filepath=self.filepath,\n",
    "            timeout=self.timeout,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "        raise NotImplementedError(\n",
    "            f'StartBackgroundPing is not implemented for architecture: {node.architecture}'\n",
    "        )\n",
    "\n",
    "class StartBackgroundPingLinuxImplementation(Task):\n",
    "    def __init__(self, address: str, filepath: str, timeout: int = 120, *args, **kwargs):\n",
    "        self.address = address.strip()\n",
    "        self.filepath = filepath\n",
    "        self.timeout = timeout\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    # TODO: implement the run() function\n",
    "    def run(self):\n",
    "        # 1. open self.filepath in write mode\n",
    "        outfile = \"<fill me in>\"\n",
    "        # 2. set the `args` argument for Popen to execute the command `ping -t self.timeout`. \n",
    "        # 3. set the optional arguments: stdout, stderr to the file object we opened for self.filepath\n",
    "        proc = subprocess.Popen(\"<fill me in>\")\n",
    "\n",
    "        time.sleep(2)\n",
    "        if (exit_code := proc.poll()) is None:  # not finished yet\n",
    "            return Success(proc.pid)\n",
    "        return Failure(f\"StartBackgroundPing failed with return code {exit_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8dac49",
   "metadata": {},
   "source": [
    "Below, we define a complementary task, StopBackgroundPing to kill our ping process so it doesn't always execute until the timeout. By specifying an optional argument `name` to our StartBackgroundPing task, we can look up the results for this task using the `self.previous_steps` object, to retrieve the PID of the ping process that we return in the StartBackgroundPing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopBackgroundPing(TaskDispatcher):\n",
    "    def __init__(self, start_ping_task_name : str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.start_ping_task_name = start_ping_task_name\n",
    "        self.linux_implementation = StopBackgroundPingLinuxImplementation(\n",
    "            ping_task_name=self.start_ping_task_name,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f'StopBackgroundPing is not implemented for {node.architecture}'\n",
    "        )\n",
    "\n",
    "class StopBackgroundPingLinuxImplementation(Task):\n",
    "    requirements = [\"sudo apt-get update\", \"sudo apt-get install -y tcpdump\", \"sudo apt-get install -y procps\"]\n",
    "\n",
    "    def __init__(self, ping_task_name: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ping_task_name = ping_task_name\n",
    "\n",
    "    def run(self):\n",
    "        signal.signal(signal.SIGCHLD, signal.SIG_IGN)\n",
    "        pid = self.previous_steps.get(self.ping_task_name, [Failure(\"Named StartBackgroundPing not found\")])[-1]\n",
    "        if isinstance(pid, Failure):\n",
    "            return pid\n",
    "\n",
    "        pid = pid.unwrap()\n",
    "        return subprocess.check_output([\"kill\", str(pid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a198de",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Now we will define a new task, GetFileContents that will output the results that we wrote to a file in the StartBackgroundPing task. This task simply prints the content of a file to stdout.\n",
    "\n",
    "Implement the **run()** function in the **GetFileContents** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetFileContents(TaskDispatcher):\n",
    "    def __init__(self, filepath: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linux_implementation = GetFileContentsLinuxImplementation(\n",
    "            filepath=filepath, name=self.name\n",
    "        )\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "        raise NotImplementedError(\n",
    "            f\"GetFileContents is not implemented for architecture: {node.architecture}\"\n",
    "        )\n",
    "\n",
    "class GetFileContentsLinuxImplementation(Task):\n",
    "    def __init__(self, filepath: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "\n",
    "    # TODO: implement the run() function\n",
    "    def run(self):\n",
    "        # 1. set the arguments for subprocess.run to exectue the command `cat self.filepath`\n",
    "        # 2. set the optional argument `capture_output` to True so that stdout will be captured\n",
    "        result = subprocess.run(\"<fill me in>\")\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            return Failure(\n",
    "                result.stdout.decode(\"utf-8\").strip()\n",
    "                + \"\\n\"\n",
    "                + result.stderr.decode(\"utf-8\").strip()\n",
    "            )\n",
    "\n",
    "        return result.stdout.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82a397",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Collect latency samples to 8.8.8.8 using the new tasks we've defined. The pipeline has already been defined for you below, but requires that the StartBackgroundPing and GetFileContents tasks are implemented correctly. Plot the results. The x-axis should be the ICMP sequence number (icmp_seq), and the y-axis should the latency in milliseconds. You should observe similar values to what you observed from Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(StartBackgroundPing(address='8.8.8.8', filepath=\"/tmp/background_ping_results1.txt\", name=\"background_ping\"))\n",
    "    .then(SleepTask(30))\n",
    "    .then(StopBackgroundPing(start_ping_task_name=\"background_ping\"))\n",
    "    .then(SleepTask(2))\n",
    "    .then(GetFileContents(filepath=\"/tmp/background_ping_results1.txt\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815214e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = execute_pipeline(pipeline, working_node, 'background_ping_experiment')\n",
    "display_results(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb499b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Parse netUnicorn output\n",
    "# 2. Graph Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d2966",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Now we will use the SpeedTest task to induce extra load on the network, and simultaneously collect our lateny samples. The pipeline has already been defined for you below, but requires that the StartBackgroundPing and GetFileContents tasks are implemented correctly. Plot the results alongside the results from Task 4. The x-axis should be the ICMP sequence number (icmp_seq), and the y-axis should the latency in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(StartBackgroundPing(address='8.8.8.8', filepath=\"/tmp/background_ping_results2.txt\", name=\"background_ping_under_load\"))\n",
    "    .then(SpeedTest())\n",
    "    .then(StopBackgroundPing(start_ping_task_name=\"background_ping_under_load\"))\n",
    "    .then(SleepTask(2))\n",
    "    .then(GetFileContents(filepath=\"/tmp/background_ping_results2.txt\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf702096",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = execute_pipeline(pipeline, working_node, 'background_ping_under_load_experiment')\n",
    "display_results(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b114c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Parse netUnicorn output\n",
    "# 2. Graph Results alongside Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba261c5",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Do you observe a difference in latencies between Task 4 and Task 5? If so, what is the reason that we observe an increased latency when we are simultaneously running a speedtest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69009ff",
   "metadata": {},
   "source": [
    "Explain your answer to Task 6 below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dda2be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
