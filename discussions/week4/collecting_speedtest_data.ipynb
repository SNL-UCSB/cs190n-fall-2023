{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfe95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa716f4",
   "metadata": {},
   "source": [
    "# Discussion Section Week 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78d7d0",
   "metadata": {},
   "source": [
    "## Netunicorn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7538ba8",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "- basic building block for netUnicorn\n",
    "- Highly configurable\n",
    "- allow users to define the behavior of their experiments\n",
    "\n",
    "#### User Actions\n",
    "- file download/upload\n",
    "- streaming video (YouTube, Netflix, etc.)\n",
    "- video conferencing (Zoom, Skype, etc.)\n",
    "\n",
    "#### Network Measurements\n",
    "- Packet Captures\n",
    "- Speedtests\n",
    "- Ping / Latency Measurements\n",
    "\n",
    "#### Application Profiling\n",
    "- Measuring Quality of Experience\n",
    "    - tools such as selenium, pyautogui allow us to extract information from browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def57477",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "- Pipeline is an ordered collection of Tasks\n",
    "- Each task is executed after the previous task completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debd9c1",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "- Infrastructure contains set of nodes able to run pipelines\n",
    "- Nodes can be...\n",
    "    - different architectures\n",
    "    - VMs in the cloud\n",
    "    - raspberry pi devices\n",
    "    - your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5fb5f",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "- Deployment is a mapping of a pipeline to a node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb190220",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "- One or more deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c748b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "import requests \n",
    "import re\n",
    "import logging\n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "from sys import platform\n",
    "import os, sys\n",
    "import logging\n",
    "import json\n",
    "import threading\n",
    "\n",
    "from netunicorn.client.remote import RemoteClient, RemoteClientException\n",
    "from netunicorn.base import Experiment, ExperimentStatus, Pipeline\n",
    "from netunicorn.library.tasks.basic import SleepTask\n",
    "from netunicorn.library.tasks.measurements.ookla_speedtest import SpeedTest\n",
    "from netunicorn.library.tasks.video_watchers.youtube_watcher import WatchYouTubeVideo\n",
    "from netunicorn.library.tasks.video_watchers.vimeo_watcher import WatchVimeoVideo\n",
    "from netunicorn.library.tasks.video_watchers.twitch_watcher import WatchTwitchStream\n",
    "from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture\n",
    "from netunicorn.library.tasks.upload.fileio import UploadToFileIO\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base.task import Failure, Task, TaskDispatcher\n",
    "from netunicorn.base import Result, Failure, Success, Task, TaskDispatcher\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd036f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTask(Task):\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        return 0\n",
    "\n",
    "class DummyRepeaterTask(Task):\n",
    "    def __init__(self, lookup_for: str):\n",
    "        self.lookup_for = lookup_for\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        return f\"Dummy Task2 Success!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2756a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().then(DummyTask(name=\"dummy1\")).then(DummyRepeaterTask(lookup_for='dummy1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ee3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticattion for NetUnicorn\n",
    "NETUNICORN_ENDPOINT = os.environ.get('NETUNICORN_ENDPOINT', 'http://54.84.96.4:26611')\n",
    "NETUNICORN_LOGIN = os.environ.get('NETUNICORN_LOGIN', 'test')\n",
    "NETUNICORN_PASSWORD = os.environ.get('NETUNICORN_PASSWORD', 'test')\n",
    "client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "print(\"Health Check: {}\".format(client.healthcheck()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ab878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Client Nodes\n",
    "nodes = client.get_nodes()\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e116f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment - Map pipeline to Nodes\n",
    "working_hosts = ['dockerhost']\n",
    "working_nodes = nodes.filter(lambda node: node.name in working_hosts).take(len(working_hosts))\n",
    "experiment = Experiment().map(pipeline, working_nodes)\n",
    "print(\"Experiment: {}\".format(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set the specific Docker image to use\n",
    "#from netunicorn.base import DockerImage\n",
    "#for deployment in experiment:\n",
    "#    # you can explore the image on the DockerHub\n",
    "#    deployment.environment_definition = DockerImage(image='netunicorn/chromium:0.3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Experiment\n",
    "experiment_label = \"test_pipeline\"\n",
    "\n",
    "# Delete any previous experiments\n",
    "try:\n",
    "    client.delete_experiment(experiment_label)\n",
    "except RemoteClientException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Experiment\n",
    "client.prepare_experiment(experiment, experiment_label)\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status == ExperimentStatus.READY:\n",
    "        break\n",
    "    time.sleep(20)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Experiment\n",
    "client.start_execution(experiment_label)\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status != ExperimentStatus.RUNNING:\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccc68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results\n",
    "from returns.pipeline import is_successful\n",
    "from returns.result import Failure\n",
    "\n",
    "for report in info.execution_result:\n",
    "    print(f\"Node name: {report.node.name}\")\n",
    "    print(f\"Error: {report.error}\")\n",
    "\n",
    "    if report.result is None:\n",
    "        print(\"report.result is EMPTY..\")\n",
    "        continue\n",
    "\n",
    "    result, log = report.result  # report stores results of execution and corresponding log\n",
    "\n",
    "    # result is a returns.result.Result object, could be Success of Failure\n",
    "    print(f\"Result is: {type(result)}\")\n",
    "    if is_successful(result):\n",
    "        data = result.unwrap()\n",
    "    else:\n",
    "        data = result.failure()\n",
    "    try:\n",
    "        for key, value in data.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    except:\n",
    "        print(f\"No attribute 'items' in result\")\n",
    "\n",
    "    # we also can explore logs\n",
    "    for line in log:\n",
    "        print(line.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8dbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pipeline(curr_pipeline):\n",
    "    NETUNICORN_ENDPOINT = os.environ.get('NETUNICORN_ENDPOINT', 'http://54.84.96.4:26611')\n",
    "    NETUNICORN_LOGIN = os.environ.get('NETUNICORN_LOGIN', 'test')\n",
    "    NETUNICORN_PASSWORD = os.environ.get('NETUNICORN_PASSWORD', 'test')\n",
    "    client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "    print(\"Health Check: {}\".format(client.healthcheck()))\n",
    "\n",
    "    # Get Client Nodes\n",
    "    nodes = client.get_nodes()\n",
    "    print(nodes)\n",
    "\n",
    "    working_hosts = ['dockerhost']\n",
    "    working_nodes = nodes.filter(lambda node: node.name in working_hosts).take(len(working_hosts))\n",
    "    experiment = Experiment().map(curr_pipeline, working_nodes)\n",
    "    print(\"Experiment: {}\".format(experiment))\n",
    "\n",
    "    # Optionally set the specific Docker image to use\n",
    "    #from netunicorn.base import DockerImage\n",
    "    #for deployment in experiment:\n",
    "    #    # you can explore the image on the DockerHub\n",
    "    #    deployment.environment_definition = DockerImage(image='netunicorn/chromium:0.3.0')\n",
    "\n",
    "    # Name Experiment\n",
    "    experiment_label = \"test_pipeline\"\n",
    "\n",
    "    # Delete any previous experiments\n",
    "    try:\n",
    "        client.delete_experiment(experiment_label)\n",
    "    except RemoteClientException:\n",
    "        pass\n",
    "\n",
    "    # Prepare Experiment\n",
    "    client.prepare_experiment(experiment, experiment_label)\n",
    "    while True:\n",
    "        info = client.get_experiment_status(experiment_label)\n",
    "        print(info.status)\n",
    "        if info.status == ExperimentStatus.READY:\n",
    "            break\n",
    "        time.sleep(20)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Execute Experiment\n",
    "    client.start_execution(experiment_label)\n",
    "    while True:\n",
    "        info = client.get_experiment_status(experiment_label)\n",
    "        print(info.status)\n",
    "        if info.status != ExperimentStatus.RUNNING:\n",
    "            break\n",
    "        time.sleep(20)\n",
    "\n",
    "    # Get Results\n",
    "    from returns.pipeline import is_successful\n",
    "    from returns.result import Failure\n",
    "\n",
    "    for report in info.execution_result:\n",
    "        print(f\"Node name: {report.node.name}\")\n",
    "        print(f\"Error: {report.error}\")\n",
    "\n",
    "        if report.result is None:\n",
    "            print(\"report.result is EMPTY..\")\n",
    "            continue\n",
    "\n",
    "        result, log = report.result  # report stores results of execution and corresponding log\n",
    "\n",
    "        # result is a returns.result.Result object, could be Success of Failure\n",
    "        print(f\"Result is: {type(result)}\")\n",
    "        if is_successful(result):\n",
    "            data = result.unwrap()\n",
    "        else:\n",
    "            data = result.failure()\n",
    "        try:\n",
    "            for key, value in data.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        except:\n",
    "            print(f\"No attribute 'items' in result\")\n",
    "\n",
    "        # we also can explore logs\n",
    "        for line in log:\n",
    "            print(line.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5659b",
   "metadata": {},
   "source": [
    "### Running a Speedtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d641388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import Dict\n",
    "\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base.task import Failure, Task, TaskDispatcher\n",
    "\n",
    "\n",
    "class SpeedTest(TaskDispatcher):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linux_instance = SpeedTestLinuxImplementation(name=self.name)\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_instance\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f'SpeedTest is not implemented for architecture: {node.architecture}'\n",
    "        )\n",
    "\n",
    "\n",
    "class SpeedTestLinuxImplementation(Task):\n",
    "    requirements = [\"pip install speedtest-cli\"]\n",
    "\n",
    "    def run(self):\n",
    "        result = subprocess.run([\"speedtest-cli\", \"--simple\", \"--secure\"], capture_output=True)\n",
    "        if result.returncode != 0:\n",
    "            return Failure(\n",
    "                result.stdout.decode(\"utf-8\").strip()\n",
    "                + \"\\n\"\n",
    "                + result.stderr.decode(\"utf-8\").strip()\n",
    "            )\n",
    "\n",
    "        return \"Speedtest Finished\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(SpeedTest())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67eb73",
   "metadata": {},
   "source": [
    "### Packet Capture (Start / Stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import signal\n",
    "from typing import List, Optional\n",
    "\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base import Task, TaskDispatcher, Result, Success, Failure\n",
    "\n",
    "\n",
    "class StartCapture(TaskDispatcher):\n",
    "    def __init__(self, filepath: str, arguments: Optional[List[str]] = None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "        self.arguments = arguments\n",
    "\n",
    "        self.linux_implementation = StartCaptureLinuxImplementation(\n",
    "            filepath=self.filepath,\n",
    "            arguments=self.arguments,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f'StartCapture is not implemented for {node.architecture}'\n",
    "        )\n",
    "\n",
    "\n",
    "class StartCaptureLinuxImplementation(Task):\n",
    "    requirements = [\"sudo apt-get update\", \"sudo apt-get install -y tcpdump\"]\n",
    "\n",
    "    def __init__(self, filepath: str, arguments: Optional[List[str]] = None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.arguments = arguments or []\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def run(self) -> Result:\n",
    "        signal.signal(signal.SIGCHLD, signal.SIG_IGN)\n",
    "\n",
    "        proc = subprocess.Popen(\n",
    "            [\"tcpdump\"] + self.arguments + [\"-U\", \"-w\", self.filepath]\n",
    "        )\n",
    "        time.sleep(2)\n",
    "        if (exit_code := proc.poll()) is None:  # not finished yet\n",
    "            return Success(proc.pid)\n",
    "        return Failure(f\"Tcpdump terminated with return code {exit_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopNamedCapture(TaskDispatcher):\n",
    "    def __init__(self, start_capture_task_name: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.start_capture_task_name = start_capture_task_name\n",
    "        self.linux_implementation = StopNamedCaptureLinuxImplementation(\n",
    "            capture_task_name=self.start_capture_task_name,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f'StopCapture is not implemented for {node.architecture}'\n",
    "        )\n",
    "\n",
    "\n",
    "class StopNamedCaptureLinuxImplementation(Task):\n",
    "    requirements = [\"sudo apt-get update\", \"sudo apt-get install -y tcpdump\", \"sudo apt-get install -y procps\"]\n",
    "\n",
    "    def __init__(self, capture_task_name: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.capture_task_name = capture_task_name\n",
    "\n",
    "    def run(self):\n",
    "        signal.signal(signal.SIGCHLD, signal.SIG_IGN)\n",
    "        pid = self.previous_steps.get(self.capture_task_name, [Failure(\"Named StartCapture not found\")])[-1]\n",
    "        if isinstance(pid, Failure):\n",
    "            return pid\n",
    "\n",
    "        pid = pid.unwrap()\n",
    "        return subprocess.check_output([\"kill\", str(pid)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c84b1",
   "metadata": {},
   "source": [
    "### Uploading to FileIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uploads files to file.io -- temporary file storage\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from netunicorn.base.nodes import Architecture, Node\n",
    "from netunicorn.base.task import Task, TaskDispatcher\n",
    "\n",
    "\n",
    "class UploadToFileIO(TaskDispatcher):\n",
    "    def __init__(self, filepath: str, expires: str = \"14d\", *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linux_implementation = UploadToFileIOCurlImplementation(\n",
    "            filepath=filepath, expires=expires, name=self.name\n",
    "        )\n",
    "        self.linux_implementation.requirements = [\"sudo apt-get install -y curl\"]\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_implementation\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f\"UploadToFileIO is not implemented for architecture: {node.architecture}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class UploadToFileIOCurlImplementation(Task):\n",
    "    def __init__(self, filepath: str, expires: str = \"14d\", *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.filepath = filepath\n",
    "        self.expires = expires\n",
    "\n",
    "    def run(self):\n",
    "        command = [\"curl\", \"-F\", f\"file=@{self.filepath}\", f\"https://file.io?expires={self.expires}\"]\n",
    "        return subprocess.run(command, check=True, capture_output=True).stdout.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a332008",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(StartCapture(filepath=\"/tmp/capture.pcap\", name=\"capture\"))\n",
    "    .then(SpeedTest())\n",
    "    .then(StopNamedCapture(start_capture_task_name=\"capture\"))\n",
    "    .then(UploadToFileIO(filepath=\"/tmp/capture.pcap\", expires=\"1d\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5601943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50157976",
   "metadata": {},
   "source": [
    "### Speedtest Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import Dict\n",
    "\n",
    "from netunicorn.base.architecture import Architecture\n",
    "from netunicorn.base.nodes import Node\n",
    "from netunicorn.base.task import Failure, Task, TaskDispatcher\n",
    "\n",
    "\n",
    "class SpeedTest(TaskDispatcher):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linux_instance = SpeedTestLinuxImplementation(name=self.name)\n",
    "\n",
    "    def dispatch(self, node: Node) -> Task:\n",
    "        if node.architecture in {Architecture.LINUX_AMD64, Architecture.LINUX_ARM64}:\n",
    "            return self.linux_instance\n",
    "\n",
    "        raise NotImplementedError(\n",
    "            f'SpeedTest is not implemented for architecture: {node.architecture}'\n",
    "        )\n",
    "\n",
    "\n",
    "class SpeedTestLinuxImplementation(Task):\n",
    "    requirements = [\"pip install speedtest-cli\"]\n",
    "\n",
    "    def run(self):\n",
    "        result = subprocess.run([\"speedtest-cli\", \"--simple\", \"--secure\"], capture_output=True)\n",
    "        if result.returncode != 0:\n",
    "            return Failure(\n",
    "                result.stdout.decode(\"utf-8\").strip()\n",
    "                + \"\\n\"\n",
    "                + result.stderr.decode(\"utf-8\").strip()\n",
    "            )\n",
    "\n",
    "        return self._format_data(result.stdout.decode(\"utf-8\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_data(data: str) -> Dict[str, Dict]:\n",
    "        ping, download, upload, _ = data.split(\"\\n\")\n",
    "        return {\n",
    "            \"ping\": {\"value\": float(ping.split(\" \")[1]), \"unit\": ping.split(\" \")[2]},\n",
    "            \"download\": {\n",
    "                \"value\": float(download.split(\" \")[1]),\n",
    "                \"unit\": download.split(\" \")[2],\n",
    "            },\n",
    "            \"upload\": {\n",
    "                \"value\": float(upload.split(\" \")[1]),\n",
    "                \"unit\": upload.split(\" \")[2],\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d020ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(SpeedTest())\n",
    "    .then(SleepTask(10))\n",
    "    .then(SpeedTest())\n",
    "    .then(SleepTask(10))\n",
    "    .then(SpeedTest())\n",
    "    .then(SleepTask(10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283cd47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
